{
    "firstSection": [
    {
      "type": "markdown",
      "value": "Language is a human skill. Computers were historically very bad at language...until LLMs came along."
    },
    {
      "type": "markdown",
      "value": "For humans, language is made up of words. But an LLM has it’s own kind of word, called a “token”.<br />Tokens are the building blocks of the language of an LLM.<br>Unlike human language, tokens do not have to be words. They can be shorter than human-readable words, or they can be multiple words together."
    },
    {
      "type": "markdown",
      "value": "Each model has its own “dictionary” of sorts based on its tokenization. The tokens are the vocabulary that allow a model to interpret text and to write new text."
    },
    {
      "type": "markdown",
      "value": "Choosing which dictionary to use is an important step in the process: adjust the slider to see how it affects the model below."
    }
  ],
  "secondSection": [
    {
      "type": "markdown",
      "value": "Many people think of LLMs as a sort of “black box”: you ask a question, and an answer magically appears! "
    },
    {
      "type": "markdown",
      "value": "Tokens act as the bridge into and out of an LLM. But there are ways to understand these models—and starting with tokens can help!"
    },
    {
      "type": "markdown",
      "value": "How does a model make connections between words? How does it understand something?"
    },
    {
      "type": "markdown",
      "value": "The Distributional Hypothesis states that words that occur in the same contexts tend to have similar meanings. So how does an LLM group different words?"
    },
    {
      "type": "markdown",
      "value": "By passing some text into a model, we can watch how it is grouped and re-grouped into different clusters (see footnote) at each layer."
    },
    {
      "type": "markdown",
      "value": "And finally, at the final layer, we can see how the model will likely behave when interpreting text."
    }
  ]
}